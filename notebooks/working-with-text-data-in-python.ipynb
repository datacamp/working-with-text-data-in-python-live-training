{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "working-with-text-data-in-python.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7Ptn0A2jq9Y",
        "colab_type": "text"
      },
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/datacamp/python-live-training-template/blob/master/assets/datacamp.svg?raw=True\" alt = \"DataCamp icon\" width=\"50%\">\n",
        "</p>\n",
        "<br><br>\n",
        "\n",
        "# **Working with Text Data in Python**\n",
        "\n",
        "Welcome to this hands-on training where you will beging to learn how to work with text data in Python! In this session you will learn:\n",
        "\n",
        "- How to explore and visualize your text data.\n",
        "- How to manipulate and clean text data for further analysis.\n",
        "- The basics of regex, and how to use it to filter a DataFrame.\n",
        "- How to use prepare a template that is easily reusable.\n",
        "\n",
        "## **The Dataset**\n",
        "\n",
        "The dataset to be used in this webinar is a CSV file named `wine_reviews.csv`, which contains data on wine reviews. In particular, it contains the following columns:\n",
        "\n",
        "### Columns:\n",
        "\n",
        "`country`: The country that the wine is from\n",
        "\n",
        "`description`: The review.\n",
        "\n",
        "`designation`: The vineyard within the winery.\n",
        "\n",
        "`points`: The number of points awarded to the wine on a scale from 1-100.\n",
        "\n",
        "`price`: The cost of the wine.\n",
        "\n",
        "`province`: The province or state where the wine originated from.\n",
        "\n",
        "`region`: The wine growing area within the province or state.\n",
        "\n",
        "`variety`: The type of grapes used to make the wine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC1nj_4Ijq9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load resources\n",
        "import pandas as pd\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from collections import Counter\n",
        "\n",
        "# Set pandas columns to display at max width\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Set seaborn aesthetic features to pretty up our plots\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHIC32FIjq9e",
        "colab_type": "text"
      },
      "source": [
        "## **Import wine data, and look at the first five rows**\n",
        "Let's first import the data which is stored in the csv `wine_reviews.csv` and inspect it. We will use:\n",
        "- `read_csv()` to read the csv file as a DataFrame.\n",
        "- `.head()` to view the first five rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdpkNyHUjq9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the csv and assign to the DataFrame 'wine_df'\n",
        "wine_df = pd.read_csv('https://github.com/datacamp/working-with-text-data-in-python-live-training/blob/master/data/wine_reviews.csv?raw=true')\n",
        "\n",
        "# View the first five rows\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNntcUwhjq9j",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** It looks as though there are a variety of different cases in the `variety` column, which we will need to address later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M5qr02_jq9k",
        "colab_type": "text"
      },
      "source": [
        "**Further inspection of our data**\n",
        "---\n",
        "First, now that we have an idea how our data is structured, and a little bit about what it contains, let's dig into the details a bit more. To do so, we will use: \n",
        "- `.info()` method on the DataFrame to learn about the data types and missing values.\n",
        "- `.sort_values()` to reorder the DataFrame by a given series.\n",
        "- `.unique()` to access the unique values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUIEH9wUjq9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display key information about the DataFrame\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlG_IbQ1jq9p",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** The two numeric columns, points and price, are correctly specified as integers and floats. However, it appears as though there are a lot of missing values for the designation column, which specifies what winery the wine originated from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cREjQjJjq9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Access the variety column, sort them alphabetically, and select only the unique values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j07za4Ujq9t",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** Due to extra spaces and inconsistencies in case, there are many duplicate entries of wine varieties that we will need to address."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxlY9Ytfjq9t",
        "colab_type": "text"
      },
      "source": [
        "## **Cleaning the data**\n",
        "As observed when exploring data, the `designation` column has missing values. One strategy to follow could be filling missing values with the name of the winery attached with `'- unknown'`. To fill out missing values, we can use the `.fillna()` method which takes in the following argument:\n",
        "- Here we will pass the `winery` series of our DataFrame, and then concatenate `- unknown`.\n",
        "- We will also use the `inplace` argument to apply this operation directly to our DataFrame.\n",
        "\n",
        "But first, let's go over string **concatenation**. In the example below, we join the word `\"the\"` with our `x` variable containing `\"winery\"`, and separate the two words by also adding a space (`\" \"`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHXX6lJujq9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create two variables storing the words of interest\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Combine the words with a space\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxudfmH4jq9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fill our designation column with the name of the winery and 'unknown'\n",
        "\n",
        "\n",
        "# Sample the DataFrame to see the result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqb2FoP4jq91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use .info() again to ensure that we have no more missing values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZq_ddQWjq96",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** Currently, there are a number of location attributes scattered across columns. While it is useful to have them separately, let's also make a column that combines this data into a useful `location` column. \n",
        "\n",
        "In particular, let's take the first three characters of the `country` name, and then combine them with the `region`. To do so, we will use:\n",
        "- String concatenation, which we used earlier.\n",
        "- The `.str.upper()` method, which returns an uppercase version of the string.\n",
        "- String indexing (which we will go over below):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKvVHBIhjq96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print out the first letter of x (which is storing 'winery')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EmcybHVjq99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print out the first four letters\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWQxSZJjjq-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print from the fourth letter until the end\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72uIkCkOjq-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a location column, and assign to it the region, \n",
        "# a hyphen, and the first two characters of the country column in upper case\n",
        "\n",
        "\n",
        "# Check our data with a random sample\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0Sj4Eeajq-G",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** Our `variety` column is a bit of a mess! Let's use a variety of string functions provided by pandas to set the varieties to lowercase, strip leading and trailing spaces, and replace any double spaces with single spaces!\n",
        "\n",
        "To do this, we will use (in order):\n",
        "- `str.strip()`: remove leading and trailing spaces.\n",
        "- `str.lower()`: convert the string to lowercase.\n",
        "- `str.replace()`: replace a given pattern or string with another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffHRr954jq-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove leading and trailing spaces from the variety column\n",
        "\n",
        "\n",
        "# Set the variety names to lower case\n",
        "\n",
        "\n",
        "# Replace all double spaces with single spaces\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viHDgUNcjq-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Double check that we have a sensible list of wine varieties\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbyvMh8Cjq-N",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Q&A 1\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erneunmljq-O",
        "colab_type": "text"
      },
      "source": [
        "## **Let's build a wordcloud!**\n",
        "---\n",
        "Okay, we have some cleaned data, it's time to start exploring these reviews and learning what we can about wines. One common way of getting a visualization of text data is through a word cloud. Here, we will use:\n",
        "- `STOPWORDS`: a set of common words to eliminate from our wordcloud.\n",
        "- `.join()`: a method by which we can join together all of the reviews in our dataset so that we have one set of text for the wordcloud.\n",
        "- `WordCloud()`: a function to generate a wordcloud from a given set of text.\n",
        "- Some `matplotlib.pyplot` functions to show our wordcloud, turn off the axis, and call the plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7-W2AXJjq-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign the built-in set of STOPWORDS to a variable stopwords, and preview it\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP1EIEx5jq-S",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** As you can see, this set contains the type of words that are common and not particularly informative for our purposes (we want to learn about wine!)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwmZYoq4jq-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Join all the reviews by a space and lowercase\n",
        "\n",
        "\n",
        "# Preview first 2000 characters to see whether reviews have been joined\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UUlEsfvjq-W",
        "colab_type": "text"
      },
      "source": [
        "Initial arguments for our first `WordCloud()`:\n",
        "- `collocations`: whether we include bigrams of words (e.g. \"the wine\") or just unigrams (e.g. \"wine\").\n",
        "    - In this wordcloud, our stopwords are only built for individual words, rather than bigrams. So let's turn this off.\n",
        "- `width` and `height`: width and height of the wordcloud canvas\n",
        "- `background_color`: the color of the background\n",
        "- `stopwords`: words that will be eliminated from the wordcloud (in this case, the common ones we loaded in earlier)\n",
        "\n",
        "We then use the `.generate()` method to generate our wordcloud from our `text` variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivX3uhIXjq-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize wordcloud\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Generate wordcloud from our text variable    \n",
        "\n",
        "\n",
        "# Render the wordcloud as an image, turn off the axis, and show\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4ytMc7Gjq-a",
        "colab_type": "text"
      },
      "source": [
        "1. We can update our set of `stopwords` by calling `.update()`, passing in a list of words that we don't want to appear in the wordcloud.\n",
        "\n",
        "2. We can update the background color by updating the `background_color` argument.\n",
        "\n",
        "3. Lastly, we can update the size of the wordcloud by specifying the figure size in `plt.figure()`. Wordcloud is built upon `matplotlib`, so we can adjust figure characteristics by using our `plt` alias for `matplotlib.pyplot`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj93pb7bjq-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Less interesting words\n",
        "\n",
        "\n",
        "# Update our stopwords with words that aren't too interesting to us\n",
        "\n",
        "\n",
        "# Generate our wordcloud, but change the background color\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Display the wordcloud, but with updated size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLHWYBmxnUyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwJfsgOVnZiV",
        "colab_type": "text"
      },
      "source": [
        "## **Simple word count**\n",
        "While a full runthrough of preprocessing for advanced topics such as natural language processing and machine learning are beyond the scope of this live-training, let's just do a quick preview of how one might get a frequency count of words outside of a wordcloud! To do this we will use:\n",
        "- `word_tokenize()`: a function we imported earlier from `ntlk.tokenize` that will 'tokenize' or split a string into substrings based on a set of criteria. In this case, we will split based on punctuation, thereby collecting words.\n",
        "- `Counter()`: a type of dictionary from the `collections` module that stores elements as keys and their counts as values.\n",
        "- `.most_common()`: a method on a counter object that will return the _n_ most common elements.\n",
        "- `.isalpha()`: Returns True if all characters are alphabetic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7WnwmTpheL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize our existing set of text if the word is alphabetic\n",
        "\n",
        "\n",
        "\n",
        "# Filter our list for words that aren't in our existing set of stopwords\n",
        "\n",
        "\n",
        "# Preview our tokenized list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiRztY92scMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use counter to create a count of each word in our filtered list final_words\n",
        "\n",
        "\n",
        "# Use a loop to print the 10 most common tokens\n",
        "for word in word_count.most_common(10):\n",
        "  print(word[0] + \": \" + str(word[1]) + \" mentions\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbViTKFW-riJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check word count for 'tannin' and 'tannins'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CMuf_-c-75U",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** It looks like our count could be more accurate, as there are nearly identical words included!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep5zq9J9_L_5",
        "colab_type": "text"
      },
      "source": [
        "## **Stemming and Lemmatization**\n",
        "### **Stemming**\n",
        "There are a few ways we can go about fixing this. First, there is stemming, which is an algorithmic way of reducing words to their root form. However, in doing so, it runs the risk of producing non-words as a result. Let's take a look by importing `PorterStemmer()` from `nltk.stem`.\n",
        "- `PorterStemmer()`: a popular stemmer available in the `nltk.stem` package, based on the Porter stemming algorithm.\n",
        "- `.stem()`: the method to which we pass the token we want to stem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocqyw6YFEtWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize our stemmer\n",
        "\n",
        "\n",
        "# Generate a list of test words\n",
        "test_words = ['bike', 'bikes', 'biking']\n",
        "\n",
        "# View the stemmer in action\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGdbOEW_FlSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a new list of test words\n",
        "new_words = ['lease', 'leasing', 'leases']\n",
        "\n",
        "# View the stemmer in action\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8IUI6CRGR12",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** It looks like we are already encountering limits of our stemmer! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZutD8xFHhUR",
        "colab_type": "text"
      },
      "source": [
        "### **Lemmatization**\n",
        "An approach that is slower, but relies upon linguistic rules is the process of _lemmatization_, which attemps to reduce input to its root word, or _lemma_. Unlike the algorithmic approach of stemming, lemmatization uses a corpus to ensure that the root word is an actual word. Let's use `WordNetLemmatizer()` and its corresponding method `.lemmatize()` to try this out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNaRM0u0HeN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize our lemmatizer\n",
        "\n",
        "\n",
        "# View the stemmer in action\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQw4n2I_H7rv",
        "colab_type": "text"
      },
      "source": [
        "## **A final pass through our word frequencies**\n",
        "Okay, now that we have experimented a bit, let's do a final run through our words with a lemmatizer and plot the counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjHc4bRuIM11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lemmatize our list with our lemmatizer\n",
        "\n",
        "\n",
        "# Use counter to create a count of each word in our filtered list \n",
        "\n",
        "\n",
        "# Check the success of our lemmatization\n",
        "print(\"Old count of tannin: \" + str(word_count.get('tannin')))\n",
        "print(\"New count of tannin: \" + str(new_word_count.get('tannin')))\n",
        "print(\"New count of tannins: \" + str(new_word_count.get('tannins')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U16RIhSuJ89G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert our most common words to a DataFrame for easy plotting\n",
        "\n",
        "\n",
        "# View first five rows\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1zrX_nOKolF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create a barplot with our values\n",
        "plt.barh(y=word_freq.Word, width=word_freq.Count)\n",
        "\n",
        "# Invert the y axis\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Set the title and show\n",
        "plt.title('Most common words')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abLj4kfkjq-d",
        "colab_type": "text"
      },
      "source": [
        "## **Searching for specific strings**\n",
        "Wordclouds and frequency counts are great starting steps, but to really explore our data we will probably want to be able to search it. Let's do some basic searches for mentions of oak in the `description` column of the DataFrame.\n",
        "- `str.contains()` will return a Boolean whether a given pattern or string is found in the string of the series. It is based off of `re.search`. \n",
        "    - For now, we will use the optional parameters `case` and `regex` to ensure that our search is _not_ case sensitive, and to specify that we are not using a regular expression pattern, and instead simply a string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dVeEL4tjq-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create our Boolean filter\n",
        "\n",
        "\n",
        "# Filter our DataFrame using our oak_filter and look at the first five rows\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO3zdCyejq-h",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** Take a look at the first result. Although the review does make reference to being aged in `oak`, it also references the wine coming from `Oakville`. Thus, there may be a risk that our query is grabbing descriptions that contain Oakville, and not oak."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaS0yXCajq-i",
        "colab_type": "text"
      },
      "source": [
        "**Introduction to Regular Expressions**\n",
        "---\n",
        "We could add a space after `'oak'` to ensure that we don't get Oakville, but what about when the word ends a sentence, or `'oakiness'` and `'oaky'`? Enter regular expressions, which allow us to define patterns to find and extract text.\n",
        "\n",
        "Regular expressions are strings that make use of normal and special characters to help define a pattern which we can then compare to our text of interest. Here, we will make use of a few special characters to write a pattern for `oak` and related adjectives. But first, let's try out some simple examples by using the digit special character."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oap6aZeXjq-i",
        "colab_type": "text"
      },
      "source": [
        "`\\d`: Matches any digit character (i.e. 0-9)\n",
        "\n",
        "`{}`: Quantifies the number of matches. \n",
        "- `{1,5}` will match between 1 and 5.\n",
        "- `{2,}` will match at least two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RrPofSfjq-j",
        "colab_type": "text"
      },
      "source": [
        "There are many more special characters we can use to write complex regular expression (or regex) patterns, but let's see what we can do with what we have learned so far. We will make use of the `re` package:\n",
        "- `re.findall()` will return all matches of our patterns in a given string.\n",
        "- We also prefix our pattern with `r` to denote it as a raw string, so Python interprets our backslashes correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7Yuj011jq-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a very contrived test string\n",
        "test_string = \"\"\"\n",
        "This tremendous 100% varietal wine hails from Oakville \n",
        "and was aged over three years in oak. Juicy red-cherry fruit \n",
        "and a compelling hint of caramel greet the palate, framed by elegant, \n",
        "fine tannins and a subtle 20% minty tone in the background. \n",
        "Balanced and rewarding from start to finish, \n",
        "it has years ahead of it to develop further nuance. There are absolutely no\n",
        "bad tannins in this wine. But there is a tasty tannin.\n",
        "Enjoy 2022–2030.\"\"\"\n",
        "\n",
        "# Let's find all digits in this review\n",
        "re.findall(r\"\\d\", test_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HpWVoPFjq-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's find all years represented in the format XXXX in this review\n",
        "re.findall(\"\\d{4}\", test_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPmeILgbjq-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's find all percentages (with between 1 and 3 digits, followed by a percentage sign)\n",
        "re.findall(\"\\d{1,3}%\", test_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdinVaQBjq-t",
        "colab_type": "text"
      },
      "source": [
        "### **Let's expand a bit on some other special characters before diving back into our dataset!**\n",
        "\n",
        "`\\w`: Matches any alphanumeric character or underscore (i.e. A-Z, a-z, 0-9, \\_)\n",
        "\n",
        "`+`: Matches between 1 or more of the preceding character.\n",
        "\n",
        "`\\s`: Matches any white space character, such as spaces, tabs, and line breaks.\n",
        "\n",
        "`?`: Matches 0 or more of the preceding character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdAZEpPTjq-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find all mentions of tannin (or tannins), as well as the word that precedes it for context\n",
        "re.findall(r\"\\w+\\stannins?\", test_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s4Rd8Q-jq-y",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Q&A 2\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyOOmQhbjq-y",
        "colab_type": "text"
      },
      "source": [
        "## **Let's learn about oak!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKd2iozxjq-z",
        "colab_type": "text"
      },
      "source": [
        "1. First, we want to ensure that it is the beginning of the string, or preceded by a space, because there may be cases where a word contains the same characters (e.g. `'cloak`'). We do this by using two new techniques: alternation and the carat.\n",
        "- `^`: matches the position before the first character of a string.\n",
        "- `|`: acts as an or.\n",
        "    - Using `()` groups characters together.\n",
        "\n",
        "```\n",
        "(\\s|^)\n",
        "```\n",
        "\n",
        "\n",
        "- `re.search()`: returns a match object if it finds an occurence of the pattern, and `NULL` if it doesn't."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLm-Gy-5X4ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test out the pattern\n",
        "print(re.search(r\"(\\s|^)oak\", \"oaky flavors\"))\n",
        "print(re.search(r\"(\\s|^)oak\", \"flavored oak\"))\n",
        "print(re.search(r\"(\\s|^)oak\", \"cloak\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWRpeagUjq-0",
        "colab_type": "text"
      },
      "source": [
        "2. We then want to search for a capitalized or non-capitalized `'o'`. To do this, we can use a character set `[]`, which matches any character in the square brackets. We then add `'a'` and `'k'` as these characters will be in every variant of oak we want to search for.\n",
        "\n",
        "```\n",
        "[Oo]ak\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiHstZgaX6gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test out character sets\n",
        "print(re.search(r\"[Oo]ak\", \"Oak\"))\n",
        "print(re.search(r\"[Oo]ak\", \"oak\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5wMED2Tjq-0",
        "colab_type": "text"
      },
      "source": [
        "3. Next, we want to allow for variants of oakiness, Here, we use one large capturing group, and then search for any of the inner groups using `|`. \n",
        "- We look for `'iness'` **or** s or y (again using square brackets).\n",
        "    - We make this set optional with `?`.\n",
        "\n",
        "```\n",
        "((iness)|s|y)?\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIhjhNrfEahm",
        "colab_type": "text"
      },
      "source": [
        "4. Finally, we use a character set that allows for a period, a comma, or white space.\n",
        "- _Note: we also introduce a `/` before the `.` to 'cancel out' the special character and treat it as a period._\n",
        "\n",
        "```\n",
        "[/.,\\s]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRtrCMMQjq-1",
        "colab_type": "text"
      },
      "source": [
        "Putting the pieces together, we now have a pattern that will capture all references to oak that we expect to find, while also not matching with words like `'Oakville'`. Let's add these together, and then assign them to the variable `oak_pattern`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mRWEteAjq-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Search for a white space, \n",
        "    # followed by any case 'o', 'ak', \n",
        "    # and ending in 'iness', 'y', or a period, comma, or whitespace.\n",
        "oak_pattern = r\"(\\s|^)[Oo]ak((iness)|y|s)?[/.,\\s]\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LodJd05Ijq-4",
        "colab_type": "text"
      },
      "source": [
        "### **Testing our pattern**\n",
        "**Note:** It is always a good idea to test that your regular expression is returning the results that you would expect, especially when you are working with longer and more complex patterns. There are many resources online where you can test patterns, such as www.regexr.com\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHPhzL9Qjq-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use our pattern to search a string that contains Oakville but not explicitly oak\n",
        "x = re.search(oak_pattern, \"This tremendous 100% varietal wine hails from Oakville.\")\n",
        "\n",
        "# If a match is found, let us know!\n",
        "if x:\n",
        "    print(\"Yes, an oak match!\")\n",
        "else:\n",
        "    print(\"No, oak isn't here!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kCtg2Pljq-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use our pattern to search a string that contains a reference to something being 'oaky'\n",
        "x = re.search(oak_pattern, \"This tremendous wine is oaky.\")\n",
        "\n",
        "# If a match is found, let us know!\n",
        "if x:\n",
        "    print(\"Yes, an oak match!\")\n",
        "else:\n",
        "    print(\"No, oak isn't here!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjAKl7pFjq--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View the first (and only) match\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjCyK9AJjq_B",
        "colab_type": "text"
      },
      "source": [
        "**Filtering the DataFrame using regex to find interesting patterns**\n",
        "---\n",
        "Now that we have a functioning pattern, we can use it to gain insights about the oakiness of wines. First, we use our pattern to filter the DataFrame, again using `str.contains()`, but this time using a regular expression.\n",
        "\n",
        "We can assign this filtered DataFrame to a new one, titled `oak_wines`, which we can use for further analyses. Let's also call `.head()` to do a sense check on the new DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD1SqAO4jq_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filter our DataFrame for descriptions matching our pattern, and assign to `oak_wines`\n",
        "\n",
        "\n",
        "# View the first five rows of our new DataFrame\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l_iP-Z5jq_F",
        "colab_type": "text"
      },
      "source": [
        "### **Performing some comparisons**\n",
        "Wonderful! Now, let's start to get an idea of the ratios of oakiness between varieties of wines. Let's start by grouping our two DataFrames, `oak_wines` and `wine_df` by the variety and counting the number of references.\n",
        "\n",
        "To do so, we will use:\n",
        "- `.groupby()` to group by the `variety`.\n",
        "- `.count()` to aggregate by the count of different wines.\n",
        "- `.sort_index()` so that we have an alphabetically sorted index to use for plotting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVb9qgarjq_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Group our oak DataFrame by variety, count it, and sort the index in descending alphabetical order\n",
        "oak_grouped = \n",
        "\n",
        "# Group our original DataFrame by variety, count it, and sort the index in descending alphabetical order\n",
        "wine_grouped = \n",
        "\n",
        "# Display the two grouped DataFrames\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5TnmHL0jq_J",
        "colab_type": "text"
      },
      "source": [
        "### **Plot our ratios**\n",
        "Let's start by doing a simple plot of the grouped DataFrames. By overlaying the `oak_grouped` data over the `wine_grouped` data, we can get a rough visualization of the ratios of oaky wines. To do this, we will use `matplotlib.pyplot.barh` to make two horizontal barplots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-95nUNyTjq_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot a horizontal bar chart of the count of varieties in 'lightsalmon'\n",
        "plt.barh(wine_grouped.index, wine_grouped, color='lightsalmon')\n",
        "\n",
        "# Plot a horizontal bar chart of the count of oaky varieties in 'firebrick'\n",
        "plt.barh(oak_grouped.index, oak_grouped, color='firebrick')\n",
        "\n",
        "# Give the plot a title\n",
        "plt.title(\"Oak Wine Counts by Variety\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H77iMr4mjq_N",
        "colab_type": "text"
      },
      "source": [
        "### **Calculate ratios**\n",
        "Clearly there are some varieties that are more likely to be described as oaky than others. Let's create a Boolean (True/False) column called `'oaky'` using our pattern, and then use a `groupby()` to calculate the percentage of each variety that is described as oaky.\n",
        "\n",
        "**Note:** When calculating the `.mean()` of a Boolean column, `pandas` treats True as 1 and False as 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3SaaiaKjq_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a new Boolean column based on whether the review contains 'oak'\n",
        "\n",
        "\n",
        "# Group the DataFrame by variety, take the mean, and select the 'oaky' column\n",
        "\n",
        "\n",
        "# View the resulting percentages\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMhAeFfyjq_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create another horizontal bar plot of the frequencies\n",
        "plt.barh(oak_freq.index, oak_freq)\n",
        "\n",
        "# Title the plot\n",
        "plt.title(\"Wines by level of Oakiness\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7JtHhKcjq_W",
        "colab_type": "text"
      },
      "source": [
        "**Finally, let's produce some replicable output!**\n",
        "---\n",
        "Let's create some variables from our filtered datasets, and use these to write a replicable expression that adapts based on new data. We can generate some simple summaries using:\n",
        "- `len()` to find the length of the two DataFrames.\n",
        "- `.idmax()` to return the index of the row with the highest value (i.e. the wine with the highest oaky percentage)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQKGop0kjq_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count the number of rows in the two DataFrames\n",
        "oak_num = \n",
        "wine_num = \n",
        "\n",
        "# Select the wine with the highest percentage of oakiness\n",
        "oak_wine = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPyG3yNPjq_a",
        "colab_type": "text"
      },
      "source": [
        "### **Using F strings**\n",
        "Okay, now let's embed our three variables into an f-string. F-strings allow us to insert our variables into strings using curly brackets `{}`. We simply need to add an `f` as a prefix to our string and call it inside a print function.\n",
        "\n",
        "We now have a simple and dynamic summary of our data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTn_Vz6_jq_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use an f-string to print a written description of our data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYAK1okBjq_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update our variables and print again\n",
        "oak_num = \n",
        "wine_num = \n",
        "oak_wine = \n",
        "\n",
        "print(f\"There were {oak_num} mentions of 'oak' from amongst {wine_num} reviews. The most oaky wine was {oak_wine}.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ycprbl9jq_i",
        "colab_type": "text"
      },
      "source": [
        "## **What's next?**\n",
        "Now that you have started your Pythonic-text journey, there are a variety of more advanced topics for you to tackle!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkJOhU6wjq_j",
        "colab_type": "text"
      },
      "source": [
        "<a href = \"https://learn.datacamp.com/courses/regular-expressions-in-python\"><img src = \"https://assets.datacamp.com/production/course_17118/shields/original/shield_image_course_17118_20200109-1-1b7rdip?1578597449\" width=100pt align=left></a><br><br>&nbsp;&nbsp;&nbsp;**Further Experience with Regular Expressions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cucS12-9jq_j",
        "colab_type": "text"
      },
      "source": [
        "<a href = \"https://learn.datacamp.com/courses/sentiment-analysis-in-python\"><img src = \"https://assets.datacamp.com/production/course_16852/shields/original/shield_image_course_16852_20190816-1-1drnml4?1565953559\" width=100pt align=left></a><br><br>&nbsp;&nbsp;&nbsp;**Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IAxZ7F_jq_k",
        "colab_type": "text"
      },
      "source": [
        "<a href = \"https://learn.datacamp.com/courses/feature-engineering-for-machine-learning-in-python\"><img src = \"https://assets.datacamp.com/production/course_14336/shields/original/shield_image_course_14336_20190428-1-1s1qt3h?1556485075\" width=100pt align=left></a><br><br>&nbsp;&nbsp;&nbsp;**Feature Engineering for Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpmSre25jq_k",
        "colab_type": "text"
      },
      "source": [
        "<a href = \"https://learn.datacamp.com/courses/introduction-to-natural-language-processing-in-python\"><img src = \"https://assets.datacamp.com/production/course_3629/shields/original/shield_image_course_3629_20200424-1-1jg2tak?1587716990\" width=100pt align=left></a><br><br>&nbsp;&nbsp;&nbsp;**Natural Language Processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nRgZsg1jq_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}